{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7cc46d3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef095d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fc416",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff8ab2",
   "metadata": {},
   "source": [
    "### Load train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46851768",
   "metadata": {},
   "source": [
    "DO NOT modify the cell below, this will load our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9878d",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e5b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = None # <- This is a hyperparameter for you to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76601c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d4684",
   "metadata": {},
   "source": [
    "I recommend leaving the test dataloader without shuffling and batch size of 1 to ensure we can reproduce results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da4077",
   "metadata": {},
   "source": [
    "### Define tranforms that will happen to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19896d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Define appropriate data transforms for training and validation\n",
    "\n",
    "Hints:\n",
    "- Use data augmentation for training (RandomHorizontalFlip, RandomRotation, etc.)\n",
    "- Think if you want to do some normalisation...?\n",
    "\"\"\"\n",
    "\n",
    " # YOUR CODE HERE - Define training transforms with augmentation\n",
    "training_transform = transforms.Compose([\n",
    "    # Add your transforms here\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Do you want to add tranforms to the test dataset? Have a think about it\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861702b4",
   "metadata": {},
   "source": [
    "Below we apply the transforms that you defined (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.transform = training_transform\n",
    "test_dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787c10d",
   "metadata": {},
   "source": [
    "### Visualise test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839c439",
   "metadata": {},
   "source": [
    "Lets see what classes we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df96275",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = test_dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f392396",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 10\n",
    "\n",
    "fig, ax = plt.subplots(1, N_IMAGES, figsize=(17,7))\n",
    "\n",
    "for i in range(N_IMAGES):\n",
    "    im, lbl = test_dataset[i]\n",
    "    \n",
    "    # Convert from tensor (C, H, W) to numpy (H, W, C) for matplotlib\n",
    "    im_display = im.permute(1, 2, 0)  # Change from (3, 32, 32) to (32, 32, 3)\n",
    "    \n",
    "    ax[i].imshow(im_display)\n",
    "    ax[i].set_title(f'{classes[lbl]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fef101",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d671fe",
   "metadata": {},
   "source": [
    "Define your model below. I've left the backbine and classifier structure but feel free to define the model however you like. Typically backbone will have the *feature learning* part if your CNN where as the classifier or head will have the feed forward neural network\n",
    "\n",
    "Tips:\n",
    "- Start with 3 input channels (RGB)\n",
    "- Gradually increase feature maps (64 -> 128 -> etc...)\n",
    "- Think about what kernel size and padding you will use in your `Conv2D` blocks. 3x3 convolutions with padding=1 is a good start imo\n",
    "- Don't neglect `MaxPool2d`\n",
    "- Think about `Dropout`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a40785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.5):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # TODO: Backbone - Feature extraction layers\n",
    "        self.backbone = None\n",
    "        \n",
    "        # TODO: Classifier head - Fully connected layers\n",
    "        self.classifier = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Define me\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c30a69",
   "metadata": {},
   "source": [
    "## Define the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d154c",
   "metadata": {},
   "source": [
    "You can follow my template structure below where I create a function `train_epoch` for a single forward pass and `train_model` which runs a complete training run for a given number of epochs. Alternatively, feel free to define the training loop however you like :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a26f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # YOUR CODE HERE - Implement training loop\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        # Move data to device\n",
    "        # Zero gradients\n",
    "        # Forward pass\n",
    "        # Calculate loss\n",
    "        # Backward pass\n",
    "        # Update weights\n",
    "        # Calculate accuracy\n",
    "        pass\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct_predictions / total_samples\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df7e47",
   "metadata": {},
   "source": [
    "You can optionally also create a `validate_epoch` method if you you created a **validation** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs=25, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Complete training pipeline\n",
    "    \n",
    "    Steps:\n",
    "    1. Define loss function and optimizer\n",
    "    2. Optional: Add learning rate scheduler\n",
    "    3. Training loop for specified epochs\n",
    "    4. Return trained model and training history\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Define loss function and optimizer. \n",
    "    criterion = None\n",
    "    optimizer = None\n",
    "    \n",
    "    # Optional: Learning rate scheduler\n",
    "    # scheduler = None\n",
    "    \n",
    "    # Training history -> You don't have to use this. This is used to accumulate stats about your training run\n",
    "    train_losses, train_accs = [], []\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    # Training loop\n",
    "    # TODO: YOUR CODE HERE - Implement training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        # Train\n",
    "        # Optionally print some stats for an epoch\n",
    "        # Optionally store history in train_lossess and train accs\n",
    "        # Optioanlly, if using a scheduler, do something with it\n",
    "        pass\n",
    "    \n",
    "    print(f\"\\nTraining completed! Final accuracy: {train_accs[-1]:.2f}%\")\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ffb82",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, result = train_model(model,train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc1e3a",
   "metadata": {},
   "source": [
    "#### Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1898484",
   "metadata": {},
   "source": [
    "This is optional, if you have kept you statistics about traning and validation, you can plot it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# TODO: Finish me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868701c9",
   "metadata": {},
   "source": [
    "## Test Evalution -> Do not modify the eval code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729deba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the final model on test data and print comprehensive metrics\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        test_loader: DataLoader for test data\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(\"Evaluating model on test data...\")\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for data, targets in tqdm(test_loader, desc=\"Testing\"):\n",
    "            # Move data to device\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL MODEL EVALUATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Print detailed classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(all_targets, all_predictions, target_names=classes))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ec680",
   "metadata": {},
   "source": [
    "Pass the model to the eval function to get the final result and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886be19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_final_model(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627406b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
